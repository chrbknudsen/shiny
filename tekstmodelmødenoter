fælles nordiske sprogmodeller



papirnoter

Love - baseret på et ønske om sammen at skabe transparente, demokratisk
funderede modeller, baseret på højkvalitetsdata.

Der vil laves en fælles ansøgning til euroHPC. der var meget andet 
man ville kunne samarbejde om - men man er  i tre forskellige lande, og 
derfor kommer man aldrig til at være alignet. Så derfor kommer man ikke
til at søge om andet end dette. For det kommer man ikke igennem med.

Leonora - også sverige

EuroHPC - finansieret af EU-Horizon. Og derfor kan norge være med.

de drier 8 hpc centre. Adgang er konkurrencebaseret med to årlige 
ansøgningsrunder. Offenlige projekter er der ikke mange af - og det er derfor ret let at komme til.

Pt arbejder de på Leonardo, der står i en gammel tobaksfabrik i Bologna. Den er nr. 6 på top 500 over hpc faciliteter i verden.

papir slut


svenskerne kører pt et projekt smamen med norske naitonalbibliotek på
maskinen.

pt kører de lydmodeller  -tale til text (og den anden vej)

Og en svensk/norsk sprogmodel

massively multilingual models. dansk/svensk/norsk er underrepræsenterede
i de amerikanske modeller.
De amerikanske kommercielle kører på webskrabet data - som hun betragter
som af lavere kvalitet. (?)

Der r et et perspektiv i at man vist ikke før har prøvet at træne på 
tre sprog fra samme familie.

De tester BERT T5, gpt, llama, mistral og gemma - det besvarede hvilke modeller de vil bygge.

almindelig adgang forventes september 2024. svneskerne leverer 500 GB
data. Og den model forventes at blive offentliggjort.

Svenskerne har åbenbart lov til at lave deres tdm og træning også på
ophavsretsbeskyttet data. Der er dog udfordringer i forbindelse med 
at træne data i Italien. Men svenskerne har fundet en jurist der siger at man kan distribuere modellen - så længe man gør det uafhængigt af træningsdata.


Svein Arne - Norge
NB AI-lab

AI-lab@nb.no. Fire fte, med mulighed for researchers in residense. Det lyder
en smule som Leiden. 
De har digitaliseret 95% af alle bøger i norge. 
>80% af alle avaiser.

Der er en phdafhandling/noget fra Kenneth Enevoldsen, der afdækker at den norske sprogmodel er bedre til dansk end den danske.

Han havde en graf om perplexity mål. Det skal der måske læses op på.

Et nyt projekt Mimer. Nordmændene kigger på kompensation af rettighedshavere, for at afdække værdien af ophavsretbeskyttet materiale i sprogmodeller.
Hvis det har værdi - kompenser, så man kan få bygget dem.

De øsnker at videreudvikle deres digitale norske tekskorpus.

I partnerskab med NTNU (NorwAI), Oslo universitet - institut fro informatik. Og "Sigma2" der er Deic ækvivalenten i norge.

deres korpus er både digitaliserede bøger og aviser. Offenltige websites. Sortingest, lovdata og wikipedia. Og dertil større interantiaonale datasæt, der ikke indgår i NCC - der er deres digitale tekstkorpus.


De vil træne modeller optil 7B, måske 15B. Mistral og Llama2.  Måske Bloom.

De vil træne 10-15 norske modeller. Trænes på forskellige datasæt, både med og uden ophavsretligt beskyttet materiale.

Evalueringer. læseforstårelse. Genereing af tekst, opsummering af tekst, sentiment analyse, svare på multiple choice kvisser fra NRK.

Basert på disse evalueringer, kan man så - msåke - svare på hvilken betydning
ophavsretligt beskyttet materiale - og derfra danne grunlag for en evt kompensationsaftale.

De baserer sig bl.a. på "common crawl". det er internetdata, men ikke deres netarkiv. Det er internationalt høstet data. Og norske jurister vurderer at man godt må bruge det - så længe man ikke distribuerer det.

Cecile lyser op både ved svenskernes mulighed. og nordmændenes overvejelser om kompensationsordninger. Denne forventes baseret på en tidligere model - hvor løsningen var at staten kom med en pose penge og rettighedshaverne sagde jatak. 

De forventer ikke at der gives adgang til alle data for alle. Men modellen forventes i sidste ende at være.



per. ministeren siger at vi ikke skal lave chatgpt på dansk. Per: nej, det skla vi ikke vi skla lave det der ligger nede i kælderen langt under chatgpt. det er kulturmodeller. Må man stille sin barnevogn på fortovet?

Det vigtige er ikke teknikken. Det er rettighederne til data.

scandeval er benchmarkmodeller for de forskellige nordiske modeller.
De deler på huggingface og kildekode på github.

det var fascinerende så let det var at få adgang til infomedia som del af hopeprojektet. det har åbnet døre for efterfølgende forskningsadgagn.

Anders klint myrvold.

dataudlevering fra netarkivet er kun til forskning - baseret på en undtagelse.
public domain - alt ældre end 140.

og man kan tale om muligheder for andre datatyper.

https://gigaword.dk/

Cecile - en af udfordringerne er at vi kan udlevere ting der ikke er tilgængelig i almindelig handel. Der forsøges at argumentere med at eksempelvis aviser godt nok er tilgængelige. Men ikke i de formater vi kan levere. Kammeradvokaten er på sagen.
Rygtet om nyheder var baseret på en vurdeing af om man må træne  algoritmer baseret på ophavsmateriale. den forventes at komme i denne uge. Hun havde håbet at den var kommet til i dag.
det næste er så spørgmsålet om man må tilgængeliggøre modellerne. Og der vil være forskelle på forskellige modeller. generative modeller kan være vanskeligere.
Og så er der persondatasporet. Alene det at køre en algoritme på personholdigt data har været betragtet osm databehandling. tilsynet lyder osm om at de godt kan se at der er en forskel. Hvis ikke der er persondata i outputtet - lyder det som om man må.

Deic

eurocc2

primært gennemgang af hvilke hpc-faciliter de kan give adgang til/hjælpe med adgang til.


Rigsarkivet
